{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cell purpose:\n",
        "# Install necessary packages used later (XGBoost, scikit-learn, pandas, joblib, streamlit, pyngrok)\n"
      ],
      "metadata": {
        "id": "-0H72ow7dAqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Python packages quietly (no verbose output).\n",
        "!pip install xgboost scikit-learn pandas joblib streamlit pyngrok --quiet\n",
        "\n"
      ],
      "metadata": {
        "id": "Vn7wZ4bz2RQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2 Create a small sample rabies dataset and save it as CSV"
      ],
      "metadata": {
        "id": "hW0OFs21dYAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell purpose:\n",
        "# Create a small CSV dataset inline (string), write it to 'rabies_data.csv', then load it into a pandas DataFrame.\n",
        "# This is useful for testing the ML pipeline with a contained dataset.\n",
        "\n",
        "\n",
        "\n",
        "# Import pandas library for handling tabular data and CSV reading/writing.\n",
        "import pandas as pd\n",
        "\n",
        "# Create a multi-line string that holds CSV formatted data for rabies cases.\n",
        "data = \"\"\"animal_alive,animal,PEP_RECOMMENDED,VISIT_STATUS,victim_environment,animal_environment,symptoms,rabies_status\n",
        "Yes,Dog,Yes,Visited,Urban,Urban,Fever,1\n",
        "No,Dog,Yes,Visited,Rural,Urban,Aggression,1\n",
        "Yes,Cat,No,Not Visited,Urban,Urban,None,0\n",
        "Yes,Dog,Yes,Visited,Urban,Rural,Fever,1\n",
        "No,Dog,Yes,Visited,Rural,Rural,Paralysis,1\n",
        "Yes,Other,No,Not Visited,Urban,Urban,None,0\n",
        "Yes,Cat,No,Visited,Urban,Urban,None,0\n",
        "Yes,Dog,Yes,Visited,Urban,Urban,Aggression,1\n",
        "No,Dog,Yes,Visited,Rural,Rural,Foaming,1\n",
        "Yes,Dog,No,Not Visited,Urban,Rural,None,0\n",
        "\"\"\"\n",
        "\n",
        "# Open (or create) a file named 'rabies_data.csv' in write mode, and assign the file handle to f.\n",
        "with open(\"rabies_data.csv\", \"w\") as f:\n",
        "    # Write the CSV formatted string held in 'data' to the file 'rabies_data.csv'.\n",
        "    f.write(data)\n",
        "\n",
        "# Read the CSV file 'rabies_data.csv' we just created into a pandas DataFrame named df.\n",
        "df = pd.read_csv(\"rabies_data.csv\")\n",
        "\n",
        "# Print a confirmation message showing that the dataset file was created and display its shape (rows, columns).\n",
        "print(\"Dataset created successfully! Shape:\", df.shape)\n",
        "\n",
        "# Display the first few rows of the DataFrame (works in notebooks; here we call head()).\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "lUp4cQar2Sef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3 Preprocessing, pipeline creation, model training, evaluation and saving"
      ],
      "metadata": {
        "id": "E6-pSPBIdq1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell purpose:\n",
        "# - Define the ML pipeline (preprocessing + XGBoost classifier).\n",
        "# - Split data into train/test.\n",
        "# - Train the model, evaluate it, and save the trained pipeline to disk using joblib.\n",
        "# Each original code line is preserved; comments above each line explain its role.\n",
        "\n",
        "\n",
        "# Import train_test_split for splitting data into training and testing sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import OneHotEncoder to convert categorical variables into a numeric one-hot representation.\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Import ColumnTransformer to apply transformations to specific columns (like categorical columns).\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Import Pipeline to chain preprocessing and model steps together.\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Import SimpleImputer to fill missing values (imputation) with a chosen strategy.\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Import the XGBoost classifier model class.\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Import joblib to save/load the trained pipeline to/from disk.\n",
        "import joblib\n",
        "\n",
        "# Import accuracy and classification report metrics to evaluate the model's performance.\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Define the name of the target column in the DataFrame.\n",
        "target = 'rabies_status'\n",
        "\n",
        "# Create feature matrix X by dropping the target column from df (so X contains only input features).\n",
        "X = df.drop(columns=[target])\n",
        "\n",
        "# Create label vector y which contains the target values (0 or 1).\n",
        "y = df[target]\n",
        "\n",
        "# Automatically detect categorical columns by selecting columns with dtype object, and convert to a list.\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Create a ColumnTransformer named preprocessor:\n",
        "# For categorical columns, run a pipeline that first imputes missing values using the most frequent value,\n",
        "# then applies one-hot encoding while ignoring unknown categories at transform time.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ]), cat_cols)\n",
        "    ],\n",
        "    # Pass through any columns not specified in transformers unchanged.\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Build a full ML pipeline that first runs the preprocessor, then fits the XGBoost classifier.\n",
        "pipeline = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('clf', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
        "])\n",
        "\n",
        "# Split the dataset into training and test sets.\n",
        "# test_size=0.2 means 20% of the data is reserved for testing; random_state ensures reproducibility.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the pipeline on the training data (this runs preprocessing - then trains the classifier).\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained pipeline to make predictions for the test set.\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Print a confirmation that the model training completed successfully.\n",
        "print(\"Model trained successfully!\")\n",
        "\n",
        "# Compute and print the accuracy score comparing true test labels to predicted labels.\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Print a detailed classification report (precision, recall, f1-score) to better understand per-class performance.\n",
        "print(\"\\n Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the entire pipeline object (preprocessing + model) to disk as 'xgb_rabies_pipeline.pkl' using joblib.\n",
        "joblib.dump(pipeline, \"xgb_rabies_pipeline.pkl\")\n",
        "\n",
        "# Print confirmation that the pipeline was saved to the file.\n",
        "print(\"\\n Model saved as xgb_rabies_pipeline.pkl\")\n",
        "\n"
      ],
      "metadata": {
        "id": "SdjyrbfJ2VOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4 Save Streamlit app to file (app.py)"
      ],
      "metadata": {
        "id": "GraymyQMd-wY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rabies Prediction App\n",
        "# Cell purpose:\n",
        "# This file creates a complete Streamlit app for rabies risk prediction.\n",
        "# Features included:\n",
        "# Multi-symptom input\n",
        "# Bite location and exposure type\n",
        "# Smart rule-based alerts\n",
        "# Dynamic progress bar for risk\n",
        "# Color-coded risk labels\n",
        "# ML prediction with rule-based override\n",
        "\n",
        "%%writefile app.py\n",
        "\n",
        "\n",
        "# IMPORT LIBRARIES\n",
        "import streamlit as st           # Streamlit for interactive web apps\n",
        "import pandas as pd              # Pandas to create structured DataFrames for ML input\n",
        "import joblib                    # Joblib to load the saved ML pipeline (.pkl)\n",
        "\n",
        "\n",
        "# LOAD THE TRAINED MODEL\n",
        "# Load the saved ML pipeline (preprocessing + XGBoost model)\n",
        "pipeline = joblib.load(\"xgb_rabies_pipeline.pkl\")  # Replace with your pipeline path\n",
        "\n",
        "# APP TITLE AND INTRODUCTION\n",
        "\n",
        "st.title(\"Rabies Prediction App\")  # Main title displayed at the top\n",
        "st.write(\"AI/ML based prediction model for Rabies in humans based on exposure details.\")  # Short description\n",
        "st.header(\"Enter Patient / Animal Details\")  # Header for input section\n",
        "\n",
        "\n",
        "# INPUT FIELDS SECTION\n",
        "\n",
        "# Dropdown for whether the animal is alive\n",
        "animal_alive = st.selectbox(\"Is the animal alive?\", [\"Yes\", \"No\"])\n",
        "# Dropdown for the type of animal\n",
        "animal = st.selectbox(\"Animal Type\", [\"Dog\", \"Cat\", \"Other\"])\n",
        "# Dropdown for whether PEP was recommended\n",
        "PEP_RECOMMENDED = st.selectbox(\"Was PEP (Post Exposure Prophylaxis) recommended?\", [\"Yes\", \"No\"])\n",
        "# Dropdown for whether the victim visited a healthcare center\n",
        "VISIT_STATUS = st.selectbox(\"Visit Status\", [\"Visited\", \"Not Visited\"])\n",
        "# Dropdown for environment of the victim\n",
        "victim_environment = st.selectbox(\"Victim Environment\", [\"Urban\", \"Rural\"])\n",
        "# Dropdown for environment of the animal\n",
        "animal_environment = st.selectbox(\"Animal Environment\", [\"Urban\", \"Rural\"])\n",
        "\n",
        "\n",
        "# SYMPTOMS MULTI-SELECTION\n",
        "\n",
        "# Multi-select box allows selecting multiple symptoms at once\n",
        "# Default is \"None\" meaning no symptoms\n",
        "symptoms = st.multiselect(\n",
        "    \"Select up to 3 symptoms (choose 'None' if no symptoms):\",\n",
        "    [\n",
        "        \"None\", \"Fever\", \"Headache\", \"Fatigue\", \"Itching\" , \"Nausea\", \"Pain at bite site\",\n",
        "        \"Aggression\", \"Hydrophobia\", \"Paralysis\", \"Agitation\", \"Anxiety\",\n",
        "        \"Confusion\", \"Foaming\", \"Difficulty swallowing\", \"Excess salivation\",\n",
        "        \"Seizures\", \"Hallucinations\"\n",
        "    ],\n",
        "    default=[\"None\"]  # Default selection shown\n",
        ")\n",
        "# Convert the selected symptoms list into a single comma-separated string for ML input\n",
        "symptom_text = \", \".join(symptoms)\n",
        "\n",
        "\n",
        "# ADDITIONAL MEDICAL DETAILS\n",
        "\n",
        "# Dropdown for bite location; face/neck = high risk\n",
        "bite_location = st.selectbox(\"Bite Location:\", [\"Hand\", \"Leg\", \"Face\", \"Neck\", \"Other\"])\n",
        "# Dropdown for type of exposure; Bite = high, Scratch = medium, Lick = low\n",
        "exposure_type = st.selectbox(\"Exposure Type:\", [\"Bite\", \"Scratch\", \"Lick\", \"Other\"])\n",
        "\n",
        "\n",
        "# SMART RULE-BASED WARNING LOGIC\n",
        "\n",
        "# Strong symptoms strongly linked to rabies\n",
        "strong_symptoms = [\"Aggression\", \"Hydrophobia\", \"Paralysis\", \"Foaming\", \"Seizures\"]\n",
        "\n",
        "# Mild/general symptoms list used for rule based overrides\n",
        "mild_symptoms = [\"Fever\", \"Headache\", \"Fatigue\", \"Nausea\", \"Pain at bite site\",\n",
        "                 \"Agitation\", \"Anxiety\", \"Confusion\", \"Difficulty swallowing\", \"Excess salivation\",\n",
        "                 \"Hallucinations\"]\n",
        "\n",
        "# High-risk bite locations\n",
        "high_risk_bites = [\"Face\", \"Neck\"]\n",
        "# High-risk exposure types\n",
        "high_risk_exposure = [\"Bite\"]\n",
        "\n",
        "# Initialize pre-risk score: 0 = Low, 1 = Medium, 2 = High\n",
        "pre_risk_score = 0\n",
        "\n",
        "# Check if any strong symptoms selected ‚Üí High risk\n",
        "if any(symptom in symptom_text for symptom in strong_symptoms):\n",
        "    pre_risk_score = 2\n",
        "# Else check for mild/general symptoms (not \"None\") ‚Üí Medium risk\n",
        "elif any(symptom != \"None\" for symptom in symptoms):\n",
        "    pre_risk_score = 1\n",
        "\n",
        "# Upgrade risk if bite location or exposure type is high-risk\n",
        "if bite_location in high_risk_bites or exposure_type in high_risk_exposure:\n",
        "    pre_risk_score = max(pre_risk_score, 2)\n",
        "\n",
        "# Display pre-prediction alert to user\n",
        "if pre_risk_score == 0:\n",
        "    st.info(\"üü¢ Low risk: No major symptoms or high risk exposure detected.\")\n",
        "elif pre_risk_score == 1:\n",
        "    st.info(\"üü° Medium risk: Mild/general symptoms or moderate risk exposure.\")\n",
        "else:\n",
        "    st.warning(\"üü† High risk: Strong symptoms or high risk exposure detected. Please consult a doctor!\")\n",
        "\n",
        "\n",
        "# DYNAMIC RISK METER\n",
        "\n",
        "# Convert risk score to percentage (0 = Low, 50 = Medium, 100 = High)\n",
        "risk_percentage = (pre_risk_score / 2) * 100\n",
        "st.progress(int(risk_percentage))  # Show a progress bar\n",
        "\n",
        "# Display color-coded risk label using HTML\n",
        "if pre_risk_score == 0:\n",
        "    st.markdown(\"<h3 style='color:green;'>Low Risk</h3>\", unsafe_allow_html=True)\n",
        "elif pre_risk_score == 1:\n",
        "    st.markdown(\"<h3 style='color:orange;'>Medium Risk</h3>\", unsafe_allow_html=True)\n",
        "else:\n",
        "    st.markdown(\"<h3 style='color:red;'>High Risk</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "# CREATE DATAFRAME FOR ML PREDICTION\n",
        "\n",
        "# Combine all user inputs into a single-row DataFrame\n",
        "data = pd.DataFrame([{\n",
        "    'animal_alive': animal_alive,\n",
        "    'animal': animal,\n",
        "    'PEP_RECOMMENDED': PEP_RECOMMENDED,\n",
        "    'VISIT_STATUS': VISIT_STATUS,\n",
        "    'victim_environment': victim_environment,\n",
        "    'animal_environment': animal_environment,\n",
        "    'symptoms': symptom_text,\n",
        "    'bite_location': bite_location,\n",
        "    'exposure_type': exposure_type\n",
        "}])\n",
        "\n",
        "# PREDICTION BUTTON\n",
        "\n",
        "if st.button(\"üîç Predict Rabies Risk\"):\n",
        "    try:\n",
        "        # ML probability prediction for rabies (class 1)\n",
        "        prob = pipeline.predict_proba(data)[0][1]\n",
        "\n",
        "        # THRESHOLD ADJUSTMENT\n",
        "        # Only probabilities >= 0.5 treated as high risk\n",
        "        pred = int(prob >= 0.5)\n",
        "\n",
        "        # RULE-BASED OVERRIDE\n",
        "        # If only mild symptoms selected (not None), force Low Risk\n",
        "        if all(symptom in mild_symptoms for symptom in symptoms) and \"None\" not in symptoms:\n",
        "            pred = 0\n",
        "\n",
        "        # DISPLAY PREDICTION RESULT\n",
        "        st.subheader(\"Prediction Result:\")\n",
        "        if pred == 1:\n",
        "            st.error(f\"üü• High Risk of Rabies (Probability: {prob:.2f})\")\n",
        "        else:\n",
        "            st.success(f\"üü© Low Risk of Rabies (Probability: {prob:.2f})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Show error if prediction fails\n",
        "        st.error(f\"‚ö†Ô∏è Prediction failed: {e}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n_h969G32d2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5 Launch Streamlit app with ngrok and create public URL"
      ],
      "metadata": {
        "id": "gvg3mibPeaLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ngrok helper to create a public tunnel, and time/os for process control.\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Replace with your own Ngrok token if needed\n",
        "NGROK_AUTHTOKEN = \"3536tjxZzkcNAbMjjVIegi0rOA9_4QgBc7uxDJWnwaxFDtsnq\"\n",
        "\n",
        "# Configure ngrok with the provided auth token so you can make public tunnels.\n",
        "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "\n",
        "# Close any existing ngrok tunnels/processes to avoid conflicts.\n",
        "ngrok.kill()\n",
        "\n",
        "# Launch the Streamlit app by issuing a system command that runs it on port 8501 in the background.\n",
        "os.system(\"streamlit run app.py --server.port 8501 &\")\n",
        "\n",
        "# Wait a few seconds to give Streamlit time to start up before creating the tunnel.\n",
        "time.sleep(8)\n",
        "\n",
        "# Create a public ngrok tunnel that forwards to local port 8501 and capture the returned public URL object.\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "# Print a friendly message and the public URL so you can open the app in a browser.\n",
        "print(\" Your Rabies Prediction App is live at:\")\n",
        "print(public_url)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wGsMLPB-2kmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
